@article{abdulhakimAnalisisDanPenerapan2021,
  title = {{Analisis dan Penerapan Algoritma Convolutional Neural Network untuk Klasifikasi Kendaraan Prioritas}},
  author = {Abdulhakim, Rijal and {Carudin} and Arif Dermawan, Budi},
  year = {2021},
  month = dec,
  journal = {Jurnal Sains dan Informatika},
  volume = {7},
  number = {2},
  pages = {135--144},
  issn = {2598-5841, 2460-173X},
  doi = {10.34128/jsi.v7i2.335},
  urldate = {2024-10-21},
  abstract = {The number of motorized vehicles in Indonesia continues to increase every year. This can cause traffic problems, one of which is congestion. One of the effects of congestion is the disruption of traffic flow. Meanwhile, according to Law of the Republic of Indonesia Number 22 of 2009 concerning road traffic and transportation in Article 134 there are 7 vehicles that must get priority on the highway. CNN is a class of deep feed-forward artificial neural networks that is widely applied to image analysis. Therefore, in this study, an analysis of the classification model was carried out for the types of fire engines, ambulances / hearses, and non-priority vehicles by applying the CNN algorithm using video data from CCTV managed by ATCS Bandung City. In this study, there are 5 different scenarios where the scenarios are distinguished by using the holdout method in data sharing and model evaluation. The results of this study indicate that the best scenario is in scenario 2 with training data of 60\%, data validation of 20\%, and testing data of 20\% successfully getting validation accuracy of 66.15\% and testing accuracy of 69.231\%.},
  copyright = {http://creativecommons.org/licenses/by-nc-sa/4.0},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\2N8BPLC3\Abdulhakim et al. - 2021 - Analisis dan Penerapan Algoritma Convolutional Neural Network untuk Klasifikasi Kendaraan Prioritas.pdf}
}

@book{alfredComputationalScienceTechnology2020,
  title = {Computational {{Science}} and {{Technology}}: 6th {{ICCST}} 2019, {{Kota Kinabalu}}, {{Malaysia}}, 29-30 {{August}} 2019},
  shorttitle = {Computational {{Science}} and {{Technology}}},
  editor = {Alfred, Rayner and Lim, Yuto and Haviluddin, Haviluddin and On, Chin Kim},
  year = {2020},
  series = {Lecture {{Notes}} in {{Electrical Engineering}}},
  volume = {603},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-15-0058-9},
  urldate = {2024-10-21},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {9789811500572 9789811500589},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\BQJ6JZDZ\Alfred et al. - 2020 - Computational Science and Technology 6th ICCST 2019, Kota Kinabalu, Malaysia, 29-30 August 2019.pdf}
}

@article{allaamKlasifikasiGenusTanaman,
  title = {{Klasifikasi Genus Tanaman Anggrek Menggunakan Metode}},
  author = {Allaam, M Raihan Rafiiful and Wibowo, Agung Toto},
  abstract = {Orchid is one of the ornamental plants that is widely cultivated. Each genus of orchids has different cultivation methods, so orchid cultivators who are just starting out need to know the genus of orchids they will cultivate first. However, not a few beginners who try to cultivate orchids without sufficient knowledge and experience, so the cultivated orchids do not grow and flower optimally. In this study, a system was built that could classify the image of orchid genera, namely the genus Cattleya, Dendrobium, Oncidium, Phalaenopsis and Vanda. Image classification is carried out using the Convolutional Neural Network (CNN) method. Where the image of the orchid as input data will be carried out according to the genus classification process. All of these classification processes are carried out through a training and testing scheme, where the training stage produces a CNN model and updated weights, then the testing stage uses the model to be tested against new image data. K-Fold Cross Validation is used at the training stage, then to evaluate the CNN model after testing, the Confusion Matrix is used. In addition, this research uses custom CNN architecture and MobileNetV2. Finally, from the total models produced, the best model is obtained with a testing accuracy score from the field of 90.44\% and a testing accuracy score from the internet of 80.54\%, and the highest F1-score of 98\% from the genus Dendrobium.},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\I8HVKCD2\Allaam and Wibowo - Klasifikasi Genus Tanaman Anggrek Menggunakan Metode.pdf}
}

@article{awangponaHyperparameterTuningDeep2021,
  title = {Hyperparameter {{Tuning}} of {{Deep}} Learning {{Models}} in {{Keras}}},
  author = {Awang Pona, KerasMohamad Zaim and K K, Krishna Prakash},
  year = {2021},
  journal = {Sparklinglight Transactions on Artificial Intelligence and Quantum Computing},
  volume = {01},
  number = {01},
  pages = {36--40},
  issn = {25830732},
  doi = {10.55011/STAIQC.2021.1104},
  urldate = {2024-10-21},
  abstract = {Hyperparameter tuning or optimization is one of the fundamental way to improve the performance of the machine learning models. Hyper parameter is a parameter passed during the learning process of the model to make corrections or adjustments to the learning process. To generalise diverse data patterns, the same machine learning model may require different constraints, weights, or learning rates. Hyperparameters are the term for these kind of measurements. These parameters have been trial-anderror tested to ensure that the model can solve the machine learning task optimally. This paper focus on the science of hyperparameter tuning using some tools with experimental values and results of each experiments. We have also documented 4 metrics to analyze the hyperparameter tuning results and benchmark the outcome.},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\XNF2Y8HI\Awang Pona and K K - 2021 - Hyperparameter Tuning of Deep learning Models in Keras.pdf}
}

@article{boonsirisumpunEnsembleMultipleCNNs2022,
  title = {Ensemble Multiple {{CNNs}} Methods with Partial Training Set for Vehicle Image Classification},
  author = {Boonsirisumpun, Narong and Surinta, Olarik},
  year = {2022},
  journal = {Science, Engineering and Health Studies},
  pages = {22020001--22020001},
  issn = {2630-0087},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\JN7TSUBH\Boonsirisumpun and Surinta - Ensemble multiple CNNs methods with partial training set for vehicle image classification.pdf}
}

@article{boonsirisumpunVehicleImageDatasets2024,
  title = {Vehicle Image Datasets for Image Classification},
  author = {Boonsirisumpun, Narong and Okafor, Emmanuel and Surinta, Olarik},
  year = {2024},
  month = apr,
  journal = {Data in Brief},
  volume = {53},
  pages = {110133},
  issn = {23523409},
  doi = {10.1016/j.dib.2024.110133},
  urldate = {2024-10-16},
  abstract = {Vehicle image recognition is a critical research area with diverse traffic management, surveillance, and autonomous driving systems applications. Accurately classifying and identifying vehicles from images play a crucial role in these domains. This work presents two vehicle image datasets: the vehicle type image dataset version 2 (VTID2) and the vehicle make image dataset (VMID). The VTID2 Dataset comprises 4,356 images of Thailand's five most used vehicle types, which enhances diversity and reduces the risk of overfitting problems. This expanded dataset offers a more extensive and varied collection for robust model training and evaluation. This dataset will be valuable for researchers focusing on vehicle image recognition tasks. With an emphasis on sedans, hatchbacks, pick-ups, SUVs, and other vehicles, the dataset allows for developing and evaluating algorithms that accurately classify different types of vehicles. The VMID Dataset contains 2,072 images of logos (called vehicle make) from eleven prominent vehicle brands in Thailand. The proposed dataset will facilitate the development of computer vision algorithms and the evaluation of learning algorithm model performance metrics. These two datasets provide valuable resources to the research community that will foster possible research advancements in vehicle recognition, vehicle logo detection or localization, and vehicle segmentation, contributing to the development of intelligent transportation systems.},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\2EZTGRPH\Boonsirisumpun et al. - 2024 - Vehicle image datasets for image classification.pdf}
}

@inproceedings{dongMobileNetV2ModelImage2020,
  title = {{{MobileNetV2 Model}} for {{Image Classification}}},
  booktitle = {2020 2nd {{International Conference}} on {{Information Technology}} and {{Computer Application}} ({{ITCA}})},
  author = {Dong, Ke and Zhou, Chengjie and Ruan, Yihan and Li, Yuzhi},
  year = {2020},
  month = dec,
  pages = {476--480},
  publisher = {IEEE},
  address = {Guangzhou, China},
  doi = {10.1109/ITCA52113.2020.00106},
  urldate = {2024-10-21},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-66540-378-8},
  file = {C:\Users\Aditya\Zotero\storage\4C9RFSYK\Dong et al. - 2020 - MobileNetV2 Model for Image Classification.pdf}
}

@article{dongVehicleTypeClassification2015,
  title = {Vehicle {{Type Classification Using}} a {{Semisupervised Convolutional Neural Network}}},
  author = {Dong, Zhen and Wu, Yuwei and Pei, Mingtao and Jia, Yunde},
  year = {2015},
  month = aug,
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  volume = {16},
  number = {4},
  pages = {2247--2256},
  issn = {1524-9050, 1558-0016},
  doi = {10.1109/TITS.2015.2402438},
  urldate = {2024-10-21},
  abstract = {In this paper, we propose a vehicle type classification method using a semisupervised convolutional neural network from vehicle frontal-view images. In order to capture rich and discriminative information of vehicles, we introduce sparse Laplacian filter learning to obtain the filters of the network with large amounts of unlabeled data. Serving as the output layer of the network, the softmax classifier is trained by multitask learning with small amounts of labeled data. For a given vehicle image, the network can provide the probability of each type to which the vehicle belongs. Unlike traditional methods by using handcrafted visual features, our method is able to automatically learn good features for the classification task. The learned features are discriminative enough to work well in complex scenes. We build the challenging BIT-Vehicle dataset, including 9850 high-resolution vehicle frontal-view images. Experimental results on our own dataset and a public dataset demonstrate the effectiveness of the proposed method.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\PYB2DC9H\Dong et al. - 2015 - Vehicle Type Classification Using a Semisupervised Convolutional Neural Network.pdf}
}

@article{durratunsafiyahPerformanceEvaluationVisionBased2018,
  title = {Performance {{Evaluation}} for {{Vision-Based Vehicle Classification Using Convolutional Neural Network}}},
  author = {Durratun Safiyah, Raja and Abdul Rahim, Zaid and Syafiq, Syamsul and Ibrahim, Zaidah and Sabri, Nurbaity},
  year = {2018},
  month = aug,
  journal = {International Journal of Engineering \& Technology},
  volume = {7},
  number = {3.15},
  pages = {86},
  issn = {2227-524X},
  doi = {10.14419/ijet.v7i3.15.17507},
  urldate = {2024-10-21},
  abstract = {Vision-based vehicle classification is a very challenging task due to vehicle pose and angle variations, weather conditions, lighting quality, and limited number of available datasets for training. It can be applied for driver assistance system and autonomous vehicles. This paper conducted a performance evaluation for this task based on three Convolutional Neural Network (CNN) models, which are simple CNN, and pre-trained CNN models that are AlexNet and GoogleNet. A dataset of more than 7000 images from the Image Processing Group (IPG) has been used for training and testing and the results indicate that AlexNet achieves the best classification result that is 65.09\%. This result is obtained because of the variations of the quality of the images.},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\ZRBMQYQQ\Durratun Safiyah et al. - 2018 - Performance Evaluation for Vision-Based Vehicle Classification Using Convolutional Neural Network.pdf}
}

@article{dwiyantoImplementasiMetodeYou2022,
  title = {{Implementasi Metode You Only Look Once (YOLOv5) Untuk Klasifikasi Kendaraan Pada CCTV Kabupaten Tulungagung}},
  author = {Dwiyanto, Ricko and Widodo, Danang Wahyu and Kasih, Patmi},
  year = {2022},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\SSZ9RH8X\Dwiyanto et al. - 2022 - Implementasi Metode You Only Look Once (YOLOv5) Untuk Klasifikasi Kendaraan Pada CCTV Kabupaten Tulu.pdf}
}

@article{fadliaKLASIFIKASIJENISKENDARAAN2019,
  title = {{KLASIFIKASI JENIS KENDARAAN MENGGUNAKAN METODE CONVOLUTIONAL NEURAL NETWORK (CNN)}},
  author = {Fadlia, Nur and Kosasih, Rifki},
  year = {2019},
  journal = {Jurnal Ilmiah Teknologi dan Rekayasa},
  volume = {24},
  number = {3},
  pages = {207--215},
  issn = {2089-8088, 1410-9093},
  doi = {10.35760/tr.2019.v24i3.2397},
  urldate = {2024-10-16},
  abstract = {Congestion is a state of heavy traffic which can be caused by many factors. One factor that causes congestion is the number of vehicles passing on the road. One effort that can be done to reduce the problem of congestion is to make a special lane that can only be passed by two, four or more wheeled vehicles. However, there are motorists who still use inappropriate paths such as on Margonda Raya Street, Depok. Two-wheeled vehicles (motorcycles) that have been prepared for special lanes, often take the lane for four-wheeled vehicles so that an activity is needed to monitor the use of traffic lanes. Therefore, in this study an introduction to the types of vehicles was made using the Convolutional Neural Network (CNN) method. The data used in this study were 120 images consisting of images of cars, motorbikes and bicycles. The results of the trial and model evaluation of the three types of vehicles using the Keras package show an accuracy of 94.4\% at the training stage and 73.3\% at the testing stage.},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\ZU6WHWWA\Fadlia and Kosasih - 2019 - KLASIFIKASI JENIS KENDARAAN MENGGUNAKAN METODE CONVOLUTIONAL NEURAL NETWORK (CNN).pdf}
}

@article{hafifahKlasifikasiJenisKendaraan2021,
  title = {{Klasifikasi Jenis Kendaraan Pada Jalan Raya Menggunakan Metode Convolutional Neural Networks (CNN)}},
  author = {Hafifah, Febri and Rahman, Sayuti and Asih, Munjiat Setiani},
  year = {2021},
  volume = {2},
  number = {5},
  abstract = {Traffic congestion is a major problem that occurs in big cities in Indonesia. This can cause various negative impacts such as waste of fuel, waste of time, and air pollution. Therefore, the government divides the types of highways and only allows large cargo trucks to pass on arterial roads. So it is necessary to have a smart city to implement government policies in order to overco me the impacts caused by traffic congestion. Classification of the types of vehicles that pass on the highway needs to be done so that there are no vehicle violations outside the specifications that are allowed to enter certain highways. Classification of vehicle types using the Convolution Neural Network (CNN) method. The architecture used is in the form of an existing CNN architecture or an existing CNN architecture, namely googlenet and shufflenet. We fine tune Googlenet and Shufflenet to get maximum accuracy. The dataset used is data taken from several CCTV camera points in several cities in Indonesia in July 2021. The proposed method can classify vehicle types with an accuracy of 95.88\% Googlenet and 96.48\% Shufflenet. Thus, it is hoped that it can contribute to researchers to develop a better CNN so that it can be implemented for the benefit of road traffic in Indonesia in the future.},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\SH3WFEA5\Hafifah et al. - 2021 - Klasifikasi Jenis Kendaraan Pada Jalan Raya Menggunakan Metode Convolutional Neural Networks (CNN).pdf}
}

@inproceedings{hichamVehicleTypeClassification2018,
  title = {Vehicle {{Type Classification Using Convolutional Neural Network}}},
  booktitle = {2018 {{IEEE}} 5th {{International Congress}} on {{Information Science}} and {{Technology}} ({{CiSt}})},
  author = {Hicham, Bensedik and Ahmed, Azough and Mohammed, Meknasssi},
  year = {2018},
  month = oct,
  pages = {313--316},
  publisher = {IEEE},
  address = {Marrakech},
  doi = {10.1109/CIST.2018.8596500},
  urldate = {2024-10-19},
  abstract = {Automation of vehicles' classification and recognition is one of the most important challenges in contemporary road safety and intelligent transportation system. The development of image processing, pattern recognition and deep learning technologies has overcome many obstacles to achieve this aim. In this paper, we present a vehicle type classification system based on deep learning technology. This system is constituted of two steps. In the first step, we apply data augmentation to attenuate the imbalanced dataset problem. In the second step, we build a convolutional neural network (CNN) model with different architectures using parameters that are learned from the training dataset. This system is part of a integrated application that will enable automated traffic signal management based on vehicle type automatic detection.},
  isbn = {978-1-5386-4385-3},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\AER26G43\Hicham et al. - 2018 - Vehicle Type Classification Using Convolutional Neural Network.pdf}
}

@article{indraImplementasiSistemPenghitung2023,
  title = {{Implementasi Sistem Penghitung Kendaraan Otomatis Berbasis Computer Vision}},
  author = {Indra, Dolly and Herman, Herman and Budi, Firman Shantya},
  year = {2023},
  month = may,
  journal = {Komputika : Jurnal Sistem Komputer},
  volume = {12},
  number = {1},
  pages = {53--62},
  issn = {2655-3198, 2252-9039},
  doi = {10.34010/komputika.v12i1.9082},
  urldate = {2024-10-21},
  abstract = {The development of computer technology today is very helpful for humans in completing their work in various fields. One application of computer technology i.e., in the field of computer vision which has a very important role for object recognition. In this study, we designed a computer vision-based automatic vehicle counting system. The system that we created uses the MobileNetV2 Single Shot Multibox Detector (SSD) which is placed on the Raspberry Pi 4 to carry out the process of classifying cars and motorcycles and the raspberry pi 4 also functions as a system controller. This automatic vehicle counter system has been integrated between Raspberry Pi 4 and a mobile application on a smartphone where the smartphone functions to display information such as day, date, month, year and together with the number of cars and motorcycles. We tested this automatic vehicle counting system on steam services (car and motorcycle washing) for 3 days where 10 vehicles were collected every day. The test results show that the system is capable of detecting cars and motorcyles with an average accuracy rate of 46.6\%.},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\QXUULRWP\Indra et al. - 2023 - Implementasi Sistem Penghitung Kendaraan Otomatis Berbasis Computer Vision.pdf}
}

@article{irfanSistemKlasifikasiKendaraan2017,
  title = {{Sistem Klasifikasi Kendaraan Berbasis Pengolahan Citra Digital dengan Metode Multilayer Perceptron}},
  author = {Irfan, Muhammad and Ardi Sumbodo, Bakhtiar Alldino and Candradewi, Ika},
  year = {2017},
  month = oct,
  journal = {IJEIS (Indonesian Journal of Electronics and Instrumentation Systems)},
  volume = {7},
  number = {2},
  pages = {139},
  issn = {2460-7681, 2088-3714},
  doi = {10.22146/ijeis.18260},
  urldate = {2024-10-21},
  abstract = {The evolution of video sensors and hardware can be used for developing traffic monitoring system vision based. It can provide information about vehicle passing by utilizing the camera, so that monitoring can be done automatically. It is needed for the processing systems to provide some information regarding traffic conditions. One such approach is to utilize digital image processing.},
  copyright = {http://creativecommons.org/licenses/by-sa/4.0},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\WCQVV4QA\Irfan et al. - 2017 - Sistem Klasifikasi Kendaraan Berbasis Pengolahan Citra Digital dengan Metode Multilayer Perceptron.pdf}
}

@article{iskandarmulyanaImplementasiDeteksiReal2022,
  title = {{Implementasi Deteksi Real Time Klasifikasi Jenis Kendaraan Di Indonesia Menggunakan Metode YOLOV5}},
  author = {Iskandar Mulyana, Dadang and Rofik, M Ainur},
  year = {2022},
  month = jul,
  journal = {Jurnal Pendidikan Tambusai},
  volume = {6},
  number = {3},
  pages = {13971--13982},
  issn = {2614-3097, 2614-6754},
  doi = {10.31004/jptam.v6i3.4825},
  urldate = {2024-10-21},
  abstract = {Indonesia has a very dense population density, especially in big cities where the roads are always crowded with various types of vehicles. During peak hours, there are many vehicles that cause traffic jams. Therefore, it is necessary to build road widening to accommodate vehicles that are crowded by various types of passing vehicles. In order to develop proper road widening in locations where congestion often occurs, a system for detecting the types of vehicles that pass on the highway is needed. The increase in various kinds of research on digital image processing, including on object detection, for classification of detection of types of vehicles on the highway. In this study, the author makes an object detection system using the YOLOV5 method to detect the type of vehicle on the highway. The author uses a dataset of 1332 images with classes of bajaj, rickshaw, bus, car, molen car, pickup truck, bicycle, motorcycle, and truck. In the results of the study using the YOLOV5 method which can recognize objects consistently with a fairly high level of accuracy and has an accuracy value of 90\%.},
  copyright = {http://creativecommons.org/licenses/by-sa/4.0},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\3BH6CH6U\Iskandar Mulyana and Rofik - 2022 - Implementasi Deteksi Real Time Klasifikasi Jenis Kendaraan Di Indonesia Menggunakan Metode YOLOV5.pdf}
}

@inproceedings{jahanRealTimeVehicleClassification2020,
  title = {Real-{{Time Vehicle Classification Using CNN}}},
  booktitle = {2020 11th {{International Conference}} on {{Computing}}, {{Communication}} and {{Networking Technologies}} ({{ICCCNT}})},
  author = {Jahan, Nusrat and Islam, Saiful and Foysal, Md. Ferdouse Ahmed},
  year = {2020},
  month = jul,
  pages = {1--6},
  publisher = {IEEE},
  address = {Kharagpur, India},
  doi = {10.1109/ICCCNT49239.2020.9225623},
  urldate = {2024-10-21},
  abstract = {Convolutional Neural Network (CNN) is a model of artificial neural networks that has grown to be most well known in computer vision assignment. In this paper work, we presented convolutional neural network for classifying four types of common vehicle in our country. Vehicle classification plays a vital role of various application such as surveillance security system, traffic control system. We addressed these issues and fixed an aim to find a solution to reduce road accident due to traffic related cases. The greatest challenge of computer vision is to achieve effective results to implement a system due to variation in shapes and colors of data. To classify the vehicle we used two methods feature extraction and classification. These two methods can straightforwardly performed by convolutional neural network. The method shows quite good performance on real-time standard dataset. Our mentioned method able to reach 97\% accuracy in case of vehicle classification.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-72816-851-7},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\PKK5KCAZ\Jahan et al. - 2020 - Real-Time Vehicle Classification Using CNN.pdf}
}

@article{jiangApplicationCropModel2014,
  title = {Application of {{Crop Model Data Assimilation With}} a {{Particle Filter}} for {{Estimating Regional Winter Wheat Yields}}},
  author = {Jiang, Zhiwei and Chen, Zhongxin and Chen, Jin and Liu, Jia and Ren, Jianqiang and Li, Zongnan and Sun, Liang and Li, He},
  year = {2014},
  month = nov,
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume = {7},
  number = {11},
  pages = {4422--4431},
  issn = {1939-1404, 2151-1535},
  doi = {10.1109/JSTARS.2014.2316012},
  urldate = {2024-10-21},
  abstract = {To improve the performance of crop models for regional crop yield estimates, a particle filter (PF) was introduced to develop a data assimilation strategy using the Crop Environment Resource Synthesis (CERES)---Wheat model. Two experiments involving winter wheat yield estimations were conducted at a field plot and on a regional scale to test the feasibility of the PF-based data assimilation strategy and to analyze the effects of the PF parameters and spatiotemporal scales of assimilating observations on the performance of the crop model data assimilation. The significant improvements in the yield estimation suggest that PF-based crop model data assimilation is feasible. Winter wheat yields from the field plots were forecasted with a determination coefficient ( ) of 0.87, a root-mean-square error (RMSE) of 251 kg/ha, and a relative error (RE) of 2.95\%. An acceptable yield at the county scale was estimated with a of 0.998, a RMSE of 9734 t, and a RE of 4.29\%. The optimal yield estimates may be highly dependent on the reasonable spatiotemporal resolution of assimilating observations. A configuration using a particle size of 50, LAI maps with a moderate spatial resolution (e.g., 1 km), and an assimilation interval of 20 d results in a reasonable tradeoff between accuracy and effectiveness in regional applications.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/OAPA.html},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\IPFT5TGI\Jiang et al. - 2014 - Application of Crop Model Data Assimilation With a Particle Filter for Estimating Regional Winter Wh.pdf}
}

@article{kherrakiDeepConvolutionalNeural2022,
  title = {Deep Convolutional Neural Networks Architecture for an Efficient Emergency Vehicle Classification in Real-Time Traffic Monitoring},
  author = {Kherraki, Amine and El Ouazzani, Rajae},
  year = {2022},
  month = mar,
  journal = {IAES International Journal of Artificial Intelligence (IJ-AI)},
  volume = {11},
  number = {1},
  pages = {110},
  issn = {2252-8938, 2089-4872},
  doi = {10.11591/ijai.v11.i1.pp110-120},
  urldate = {2024-10-21},
  abstract = {Nowadays, intelligent transportation system (ITS) has become one of the most popular subjects of scientific research. ITS provides innovative services to traffic monitoring. The classification of emergency vehicles in traffic surveillance cameras provides an early warning to ensure a rapid reaction in emergency events. Computer vision technology, including deep learning, has many advantages for traffic monitoring. For instance, convolutional neural network (CNN) has given very good results and optimal performance in computer vision tasks, such as the classification of vehicles according to their types, and brands. In this paper, we will classify emergency vehicles from the output of a closed-circuit television (CCTV) camera. Among the advantages of this research paper is providing detailed information on the emergency vehicle classification topic. Emergency vehicles have the highest priority on the road and finding the best emergency vehicle classification model in realtime will undoubtedly save lives. Thus, we have used eight CNN architectures and compared their performances on the Analytics Vidhya Emergency Vehicle dataset. The experiments show that the utilization of DenseNet121 gives excellent classification results which makes it the most suitable architecture for this research topic, besides, DenseNet121 does not require a high memory size which makes it appropriate for real-time applications.{$<$}p{$>~<$}/p{$>$}},
  copyright = {http://creativecommons.org/licenses/by-sa/4.0},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\9MQZBBAY\Kherraki and El Ouazzani - 2022 - Deep convolutional neural networks architecture for an efficient emergency vehicle classification in.pdf}
}

@inproceedings{maungmaiVehicleClassificationDeep2019,
  title = {Vehicle {{Classification}} with {{Deep Learning}}},
  booktitle = {2019 {{IEEE}} 4th {{International Conference}} on {{Computer}} and {{Communication Systems}} ({{ICCCS}})},
  author = {Maungmai, Watcharin and Nuthong, Chaiwat},
  year = {2019},
  month = feb,
  pages = {294--298},
  publisher = {IEEE},
  address = {Singapore},
  doi = {10.1109/CCOMS.2019.8821689},
  urldate = {2024-10-19},
  abstract = {Nowadays, there are many traffic surveillance systems which are installed in almost every city to record events and traffic. The surveillance system is used for various objectives, e.g. vehicles searching and real-time traffic monitoring, etc. For the searching purpose, the system can be used by policeman such as outlaw's vehicle identification in crime. Typically, the officers manually identify the vehicle in recorded video according to its appearances. Although the accuracy of this approach is good, it is time-consuming and inclined to faults due to human fatigue for long duration videos. Moreover, hiring employees is costly. Recently, there are several machine learning methods which can be applied to classify vehicles, e.g. Fuzzy Logic, Decision Tree, Adaboost, Random Forest, Neural Network, etc. Convolutional Neural Network (CNN) is also one of such methods. CNN is a type of Deep Learning which is in the category of the neural network. The method is very well-known in image recognition field at the present because of its performance. In the proposed vehicle classification, there are two vehicle characteristics, i.e. types and colors. Types consist of four classes while colors consist of seven classes. CNN is then used as to classify vehicle images. The experimental results show that CNN can achieve high performance in real-world applications.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-72811-322-7},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\X6M996RE\Maungmai and Nuthong - 2019 - Vehicle Classification with Deep Learning.pdf}
}

@article{mulyanaKlasifikasiKendaraanPada2022,
  title = {{Klasifikasi Kendaraan pada Jalan Raya menggunakan Algoritma Convolutional Neural Network ( CNN )}},
  author = {Mulyana, Dadang Iskandar and Rofik, M Ainur and Zakaria, M Ohan Zoharuddin},
  year = {2022},
  volume = {6},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\YZQBVNAY\Mulyana et al. - 2022 - Klasifikasi Kendaraan pada Jalan Raya menggunakan Algoritma Convolutional Neural Network ( CNN ).pdf}
}

@article{nouvelKlasifikasiKendaraanRoda2015,
  title = {{Klasifikasi Kendaraan Roda Empat Berbasis Knn}},
  author = {Nouvel, Ahmad},
  year = {2015},
  volume = {3},
  number = {2},
  abstract = {Abstrac - For the classification of the best car is not easy, because the choice of one another have the advantages and disadvantages of each. This paper discusses the decision to choose the best car alternative. During this time a large probability of selection is determined more by intuition and subjectivity of decision-makers, who tend to be biased considering human cognitive keterbatsan. To solve this problem the author using K Nearest Neighbor (KNN) as evidenced by weka tool, and diaplikasikasikan using matlab. Results from this experiment is that the amount of data as much as 14 have accuracy levels of 78.57\% and RMSE of 0.23, while the amount of data as much as 1728 has reached 95.78\% accuracy level, RMSE 0.19 and ROC area 0.99. Shows the greater the amount of data the higher the level accuraynya.},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\T7DTDJY3\Nouvel - 2015 - Klasifikasi Kendaraan Roda Empat Berbasis Knn.pdf}
}

@article{putraTransferLearningUntuk2023,
  title = {{Transfer Learning untuk Klasifikasi Penyakit dan Hama Padi Menggunakan MobileNetV2}},
  author = {Putra, Oddy Virgantara and Mustaqim, Muhammad Zaim and Muriatmoko, Dihin},
  year = {2023},
  month = aug,
  journal = {Techno.Com},
  volume = {22},
  number = {3},
  pages = {562--575},
  issn = {2356-2579},
  doi = {10.33633/tc.v22i3.8516},
  urldate = {2024-10-21},
  abstract = {Rice plants play an important role for food availability in Indonesia. However, many factors can affect the yield of rice plants, one of which is disease and pests in rice plants. Delays in handling rice plant diseases and pests can occur due to delays in diagnosing rice plant diseases and pests, especially in remote areas that have limited internet access and repairs. Therefore an automatic process of classifying diseases and pests in rice plants that can be implemented on devices with limited resources, such as mobile devices is urgently needed. This study compares five Transfer Learning architectures, namely MobileNet V2, NasNet Mobile, EfficientNet B7, Inception V3, VGG 16 and the simple CNN model. This study used dataset which contained 5 diseases, 3 pests and 1 healthy rice plant. Each data will pass through the preprocessing and augmentation stages. MobileNet V2 has a fairly good number of parameters and performance in classifying rice plant diseases with a total of 2,27 million parameters, 96\% accuracy, 96\% precision, 96\% recall, 99\% specificity and 96\% f1 score.},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\6G82LJE2\Putra et al. - 2023 - Transfer Learning untuk Klasifikasi Penyakit dan Hama Padi Menggunakan MobileNetV2.pdf}
}

@article{rahmanAnalisisKlasifikasiMobil2022,
  title = {{Analisis Klasifikasi Mobil Pada Gardu Tol Otomatis (GTO) Menggunakan Convolutional Neural Network (CNN)}},
  author = {Rahman, Sayuti and Titania, Adinda and Sembiring, Arnes and Khairani, Mufida and Lubis, Yessi Fitri Annisah},
  year = {2022},
  month = jul,
  journal = {Explorer},
  volume = {2},
  number = {2},
  pages = {54--60},
  issn = {2774-4647},
  doi = {10.47065/explorer.v2i2.286},
  urldate = {2024-10-16},
  abstract = {The concept of a smart city is the most important issue in the development aspect of big cities in the world. Where the city must promise a more comfortable, organized, healthy and efficient life. Smart transportation is part of a smart city that is useful for improving better urban planning. Smart transportation also applies to toll roads, such as automating toll road retribution payments. Automatic Toll Gate (GTO) in Indonesia still uses sensors. However, sensors often misclassify trailers. In addition, the use of sensors also requires additional costs in installation and maintenance. Currently, every toll gate is equipped with cameras for various purposes. By utilizing the camera for vehicle type classification, the cost of the GTO will be reduced. For this reason, utilizing a digital camera with computer vision for vehicle type classification is the solution. Convolutional Neural Networks (CNN) is the most popular technique today in solving computer vision problems. Exploit the existing CNN by replacing the last fully connected output according to the number of vehicle classes. The test results show that mobilenet V2 is better in the classification of vehicle types, the best accuracy is Alexnet 93.81\% and Mobilenet 96.19\%. Computer vision by utilizing CNN is expected to replace the use of sensors so that implementation costs are cheaper..},
  copyright = {https://creativecommons.org/licenses/by-sa/4.0},
  langid = {indonesian},
  file = {C:\Users\Aditya\Zotero\storage\R2NQ2FEJ\Rahman et al. - 2022 - Analisis Klasifikasi Mobil Pada Gardu Tol Otomatis (GTO) Menggunakan Convolutional Neural Network (C.pdf}
}

@article{rogachevAutomationProcessSelecting2020,
  title = {Automation of the Process of Selecting Hyperparameters for Artificial Neural Networks for Processing Retrospective Text Information},
  author = {Rogachev, A F and Melikhova, E V},
  year = {2020},
  month = sep,
  journal = {IOP Conference Series: Earth and Environmental Science},
  volume = {577},
  number = {1},
  pages = {012012},
  issn = {1755-1307, 1755-1315},
  doi = {10.1088/1755-1315/577/1/012012},
  urldate = {2024-10-21},
  abstract = {Neural network technologies are successfully used in solving problems from various areas of the economy - industry, agriculture, medicine. The problems of substantiating the choice of architecture and hyperparameters of artificial neural networks (ins) aimed at solving various classes of applied problems are caused by the need to improve the quality and speed of deep ins training. Various methods of optimizing ins hyperparameters are known, for example, using genetic algorithms, but this requires writing additional software. To optimize the process of selecting hyperparameters, Google research has developed the KerasTuner Toolkit, which is a user-friendly platform for automated search for optimal hyperparameter combinations. In the described Kerastuner Toolkit, you can use random search, Bayesian optimization, or Hyperband methods. In numerical experiments, 14 hyperparameters varied: the number of blocks of convolutional layers and their forming filters, the type of activation functions, the parameters of the <<dropout>> regulatory layers, and others. The studied tools demonstrated high optimization efficiency while simultaneously varying more than a dozen parameters of the convolutional network, while the calculation time on the Colaboratory platform for the studied INM architectures was several hours, even with the use of GPU graphics accelerators. For ins focused on processing and recognizing text information in natural language (NLP), the recognition quality has been improved to 83-92\%.},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\SJ3PWNNA\Rogachev and Melikhova - 2020 - Automation of the process of selecting hyperparameters for artificial neural networks for processing.pdf}
}

@misc{sandlerMobileNetV2InvertedResiduals2019,
  title = {{{MobileNetV2}}: {{Inverted Residuals}} and {{Linear Bottlenecks}}},
  shorttitle = {{{MobileNetV2}}},
  author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  year = {2019},
  month = mar,
  number = {arXiv:1801.04381},
  eprint = {1801.04381},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-10-17},
  abstract = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\Aditya\Zotero\storage\TD5F7JT2\Sandler et al. - 2019 - MobileNetV2 Inverted Residuals and Linear Bottlenecks.pdf}
}

@article{shokraviReviewVehicleClassification2020,
  title = {A {{Review}} on {{Vehicle Classification}} and {{Potential Use}} of {{Smart Vehicle-Assisted Techniques}}},
  author = {Shokravi, Hoofar and Shokravi, Hooman and Bakhary, Norhisham and Heidarrezaei, Mahshid and Rahimian Koloor, Seyed Saeid and Petr{\r u}, Michal},
  year = {2020},
  month = jun,
  journal = {Sensors},
  volume = {20},
  number = {11},
  pages = {3274},
  issn = {1424-8220},
  doi = {10.3390/s20113274},
  urldate = {2024-10-21},
  abstract = {Vehicle classification (VC) is an underlying approach in an intelligent transportation system and is widely used in various applications like the monitoring of traffic flow, automated parking systems, and security enforcement. The existing VC methods generally have a local nature and can classify the vehicles if the target vehicle passes through fixed sensors, passes through the short-range coverage monitoring area, or a hybrid of these methods. Using global positioning system (GPS) can provide reliable global information regarding kinematic characteristics; however, the methods lack information about the physical parameter of vehicles. Furthermore, in the available studies, smartphone or portable GPS apparatuses are used as the source of the extraction vehicle's kinematic characteristics, which are not dependable for the tracking and classification of vehicles in real time. To deal with the limitation of the available VC methods, potential global methods to identify physical and kinematic characteristics in real time states are investigated. Vehicular Ad Hoc Networks (VANETs) are networks of intelligent interconnected vehicles that can provide traffic parameters such as type, velocity, direction, and position of each vehicle in a real time manner. In this study, VANETs are introduced for VC and their capabilities, which can be used for the above purpose, are presented from the available literature. To the best of the authors' knowledge, this is the first study that introduces VANETs for VC purposes. Finally, a comparison is conducted that shows that VANETs outperform the conventional techniques.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\FMMT5WZM\Shokravi et al. - 2020 - A Review on Vehicle Classification and Potential Use of Smart Vehicle-Assisted Techniques.pdf}
}

@inproceedings{weiwuMethodVehicleClassification2001,
  title = {A Method of Vehicle Classification Using Models and Neural Networks},
  booktitle = {{{IEEE VTS}} 53rd {{Vehicular Technology Conference}}, {{Spring}} 2001. {{Proceedings}} ({{Cat}}. {{No}}.{{01CH37202}})},
  author = {{Wei Wu} and {Zhang QiSen} and {Wang Mingjun}},
  year = {2001},
  volume = {4},
  pages = {3022--3026},
  publisher = {IEEE},
  address = {Rhodes, Greece},
  doi = {10.1109/VETECS.2001.944158},
  urldate = {2024-10-21},
  abstract = {This paper presents a novel method of vehicle classification using parameterized model and neural networks. First, we propose the parameterized model, which can describe features of vehicle. In this model, vertices and their topological structure are regarded as the key features. Then we adopt classifier based on multi-layer perceptron networks (MLPN) to recognize vehicles. In this neural network classifier, learning algorithms based on the gradient descent method for the least exponential function error (LEFE) are adopted. Experimental results show that parameterized model can satisfactorily and effectively describe vehicles, and correct rate for vehicle recognition using neural networks classifier is more than 91\%. This novel method can be used in real world systems such as the vehicle verifying system in toll collecting station. However, it is not difficult to adapt algorithms and improve model to fit for other traffic scene.},
  isbn = {978-0-7803-6728-9},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\NLLAKPF8\Wei Wu et al. - 2001 - A method of vehicle classification using models and neural networks.pdf}
}

@incollection{wongVehicleClassificationUsing2020,
  title = {Vehicle {{Classification}} Using {{Convolutional Neural Network}} for {{Electronic Toll Collection}}},
  booktitle = {Computational {{Science}} and {{Technology}}},
  author = {Wong, Zi Jian and Goh, Vik Tor and Yap, Timothy Tzen Vun and Ng, Hu},
  editor = {Alfred, Rayner and Lim, Yuto and Haviluddin, Haviluddin and On, Chin Kim},
  year = {2020},
  volume = {603},
  pages = {169--177},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-15-0058-9_17},
  urldate = {2024-10-21},
  abstract = {Electronic Toll Collection (ETC) is an automated toll collection system that is fast, efficient, and convenient. Transponder-based ETC's such as Malaysia's SmartTag is the most common and reliable. Transponders send identification information wirelessly and the toll fee is charged accordingly. However, it is susceptible to fraudulent transactions where transponders for more expensive vehicle classes such as trucks are swapped with vehicles from cheaper classes like taxis. As such, the toll operator must be able to independently classify the vehicle class instead of relying on information sent from potentially misused transponders. In this paper, we implement an automated video-based vehicle detection and classification system that can be used in conjunction with transponder-based ETCs. It uses the Convolutional Neural Network (CNN) to classify three vehicle classes, namely cars, trucks, and buses. The system is implemented using TensorFlow and is able to obtain high validation accuracy of 93.8\% and low validation losses of 0.236. The proposed vehicle classification system can reduce the need for human operators, thus minimising cost and increasing efficiency.},
  copyright = {http://www.springer.com/tdm},
  isbn = {9789811500572 9789811500589},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\A7V47NX7\Wong et al. - 2020 - Vehicle Classification using Convolutional Neural Network for Electronic Toll Collection.pdf}
}

@article{zhuoVehicleClassificationLargescale2017,
  title = {Vehicle Classification for Large-Scale Traffic Surveillance Videos Using {{Convolutional Neural Networks}}},
  author = {Zhuo, Li and Jiang, Liying and Zhu, Ziqi and Li, Jiafeng and Zhang, Jing and Long, Haixia},
  year = {2017},
  month = oct,
  journal = {Machine Vision and Applications},
  volume = {28},
  number = {7},
  pages = {793--802},
  issn = {0932-8092, 1432-1769},
  doi = {10.1007/s00138-017-0846-2},
  urldate = {2024-10-21},
  abstract = {Vehicle classification plays an important role in intelligent transport system. However, because the conventional vehicle classification methods are not robust to variations such as illumination, weather, noise, and the classification accuracy cannot meet the requirements of practical applications. Therefore, a new vehicle classification method using Convolutional Neural Networks is proposed in this paper, which consists of two steps: pre-training and fine-tuning. In pre-training, GoogLeNet is pre-trained on ILSVRC-2012 dataset to obtain the initial model with the corresponding connection weights. In fine-tuning, the initial model is further fine-tuned on VehicleDataset which is constructed with 13,700 images in this paper to obtain the final classification model. All images in the VehicleDataset are extracted from real highway surveillance videos, including variations of illumination, noise, resolution, angle of video cameras and weather. The vehicles are divided into six categories, i.e., bus, car, motorcycle, minibus, truck and van. The performance evaluation is carried out on the VehicleDataset. The experimental results show that the proposed method can avoid the complicated process of manually extracting features and the average classification accuracy is up to 98.26\%, which is 3.42\% higher than the conventional methods using ``Feature + Classifier''.},
  langid = {english},
  file = {C:\Users\Aditya\Zotero\storage\7XIDCH6Y\Zhuo et al. - 2017 - Vehicle classification for large-scale traffic surveillance videos using Convolutional Neural Networ.pdf}
}
